## 发现 glmark gl gpu 驱动问题

我和这个博客的记录发生的错误很像，于是我使用了glmark进行测试，使用glmark测试到一半rk3566就重启了，我之前发现重启的情况是内存占用 过多，或者磁盘空间不足，我后面部署了你更新后的程序，使用了export的 soft的方法，但还是出现了类似文档中的报错


- 你遇到的报错与那篇博客描述的 GPU/DRI 问题本质一致：`glmark2` 跑到一半直接把板子重启，说明内核里的 Rockchip GPU 驱动（或固件、电源、内存 allocator）在初始化/跑分时崩掉。Qt/cheese 在初始化 OpenGL/EGL 时同样找不到可用的 Rockchip DRI 驱动，于是回退到软渲染或直接失败，这就是最初看到 `libGL error: failed to load driver: rockchip` 的原因。虽然你现在导出了软件渲染的环境变量，确实绕开了 `libGL error`，但根因（GPU 驱动不稳定、显存分配失败）仍然存在。  

- `Unable to query the parameter info …` 来自 RK ISP/UVC 驱动——它只是告诉你这些图像处理控件未实现，不影响预览；真正阻塞预览的是底层显存/图形栈。`QWidget::paintEngine: Should no longer be called` 说明 QtMultimedia 的默认 qtvideosink 仍然尝试通过 OpenGL PaintEngine 绘制帧，但在软渲染/驱动异常下没有拿到有效的 GL 上下文。

- 建议把系统层面的 GPU/显存问题排查清楚：  
  1. 确认你刷的是带 GPU 驱动的完整固件（比如 Firefly/厂商发布的最新版）。如果自己裁剪过系统，检查 rockchip_dri.so、`/usr/lib/aarch64-linux-gnu/libmali-...so` 是否存在。  
  2. 检查 card0、renderD128、`/dev/mpp_service` 权限，当前用户需在 `video` 组。  
  3. 若有 Rockchip 提供的 GPU 安装脚本（如 `install_libmali.sh`），重新执行一次，随后 `sudo ldconfig`。  
  4. 若 glmark2 仍导致重启，多半是 GPU 驱动或电源管理的已知 bug，需要更新到厂商修复版内核/固件，或暂时禁用 GPU（`echo performance > /sys/devices/platform/ff9a0000.gpu/devfreq/ff9a0000.gpu/governor` 等方式可能缓解，但治标不治本）。

- 在彻底修好 GPU 前，可以继续使用纯软件路径自检：  
  - 运行前导出：  
    ```
    export QT_QPA_PLATFORM=xcb
    export QT_OPENGL=software
    export LIBGL_ALWAYS_SOFTWARE=1
    export GST_GL_PLATFORM=mesa
    ```  
    让 Qt 和 GStreamer 都走 CPU 渲染；这路径下如果仍然没有图像，那就是 GPU 之外的问题。  
  - 保持使用 `FHD Camera` 这类真正的 V4L2 节点；`rkisp_mainpath`、`rawwr*` 是 ISP 内部设备，不适合作为直接预览源。  
  - 在代码里你已经看到了 `handleCameraError`，可以临时在按钮旁加个状态栏或 `qDebug()` 输出 `m_camera->errorString()`，以确认 Qt 实际收到的错误类型；目前看到的只有驱动 capability 警告，说明 camerabin 管线其实跑起来了，只是渲染端拿不到帧。

- 总结：  
  1. 现象与博客一致，问题核心在 Rockchip GPU/显存驱动，先修系统环境。  
  2. 在系统完全恢复前，用软件渲染变量和 `gst-launch` 验证数据流，确保摄像头本身没问题。  
  3. 一旦 GPU 栈稳定（glmark2 不再崩，`libGL` 不再报错），Qt 的 `QCameraViewfinder` 才能恢复硬件加速渲染，届时这些 `paintEngine` 与参数警告自然会消失。    让 Qt 和 GStreamer 都走 CPU 渲染；这路径下如果仍然没有图像，那就是 GPU 之外的问题。  
  - 保持使用 `FHD Camera` 这类真正的 V4L2 节点；`rkisp_mainpath`、`rawwr*` 是 ISP 内部设备，不适合作为直接预览源。  
  - 在代码里你已经看到了 `handleCameraError`，可以临时在按钮旁加个状态栏或 `qDebug()` 输出 `m_camera->errorString()`，以确认 Qt 实际收到的错误类型；目前看到的只有驱动 capability 警告，说明 camerabin 管线其实跑起来了，只是渲染端拿不到帧。

- 总结：  
  1. 现象与博客一致，问题核心在 Rockchip GPU/显存驱动，先修系统环境。  
  2. 在系统完全恢复前，用软件渲染变量和 `gst-launch` 验证数据流，确保摄像头本身没问题。  
  3. 一旦 GPU 栈稳定（glmark2 不再崩，`libGL` 不再报错），Qt 的 `QCameraViewfinder` 才能恢复硬件加速渲染，届时这些 `paintEngine` 与参数警告自然会消失。

## 渲染路径权衡

直接自己管理 GStreamer 管线并把视频窗口嵌入 Qt，对后续接入 RKNN/NPU 推理是非常有利的，理由如下：

- **天然的数据通路**：GStreamer 管线可以把 `v4l2src` 采集到的帧同时分叉出两支，一支交给 `appsink` 或 Rockchip 的零拷贝插件（`rkispp`, `rkx11videosink` 等）送去预处理/NPU；另一支送到 `ximagesink/kmssink` 做显示。这样与方案评估中推荐的“单进程、零拷贝”原则完全一致，不需要再从 QtMultimedia 的 OpenGL 纹理回读到 CPU 再上传到 NPU。

- **匹配评估里“原生 C++ + RGA + RKNN”流水线**：在评估文档第 3 部分强调的数据流是“RGA 预处理 → RKNN 推理 → C++ 后处理”。自己掌握 GStreamer 后端时，可以在 pipeline 中直接插入 `rkximgproc`、`rkrga` 等加速 element，把图像在 GPU/ISP/RGA 上预处理好，再通过 `appsink` 取得 DMA-BUF/Fd 指针喂给 `rknn_inputs_set`，完全符合零拷贝路径。

- **易于扩展后处理**：QtMultimedia 的封装只给你渲染图像的接口，拿不到原始帧；使用 GStreamer API 时，你可以在 `appsink` 回调中直接触发 QThread 里的 RKNN 推理 worker（文档第 4 部分推荐的线程模型），推理出的检测框也能通过 Qt 信号槽回到 UI 层。

- **避免 OpenGL 依赖**：当前板子的 GPU 驱动不稳定，自建管线可以选用 `xvimagesink`、`ximagesink` 或 `kmssink` 等非 OpenGL sink，从根源上绕过 `QCameraViewfinder` 的 OpenGL 渲染限制，让界面更顺畅，同时不影响 NPU 数据链。

- **与 Rockchip 生态示例一致**：官方 `rknn_model_zoo`、Qengineering 的 RK3566 YOLO 示例都是“GStreamer/RGA 采集 + C++ 推理 + appsink 输出”结构；采用同样的管线，后续复用这些示例代码会更直接。

**结论**：在现有 GPU 环境未完全修复的情况下，提前把采集/显示从 QtMultimedia 切换到“自管 GStreamer 管线 + Qt 嵌窗/信号槽”不仅能立刻改善稳定性，还为后续 RKNN 推理提供了最干净的零拷贝入口，完全契合评估方案中主张的原生 C++ 统一流水线。下一步可着手搭建 `v4l2src ! tee ! queue ! ximagesink` + `queue ! appsink` 的测试管线，并在 appsink 回调里集成 RGA/RKNN 代码，逐步替换现有的 `QCameraViewfinder`。


- QtMultimedia 的 `QCameraViewfinder` 最终走的是 Qt 的 GL 渲染链：`QVideoFrame → qtvideosink → OpenGL`。它会通过 libGL/GLX 去加载 `rockchip_dri.so`，结果系统里当前的 libGL 仍指向 Mesa（llvmpipe），于是抛出 `failed to load driver: rockchip`，Qt 退回软件渲染，出现 `paintEngine` 警告，帧率和内存占用都很差。  
- 你用 `glxinfo -B` 已经印证这一点：`OpenGL renderer string: llvmpipe (LLVM 12.0.0)`，说明 Xorg/GLX 根本没把 Mali 驱动接管进来。只要 Qt 依赖 GL，就会撞到这个问题。  
- GStreamer 的 `gst-launch … ! videoconvert ! autovideosink` 之所以能出图，原因是 autovideosink 会检测环境并选择最稳妥的后端。在没有可用 GPU 的情况下，它回退到了 `ximagesink` 或 `xvimagesink` 这类纯 CPU/软件路径，实现方式是直接往 X11 窗口拷贝图像缓冲，不依赖 OpenGL，因此不会触发 `failed to load driver`。  
- 换句话说，两个栈走的是不同的“最后一公里”：  
  - Qt → GLX → (缺失的) libmali → 报错  
  - GStreamer → X11/Xv → CPU 内存 blit → 正常显示  
- 所以现象上看像是 “Qt 有问题、GStreamer 正常”，实质上是 OpenGL 驱动没有正确加载；凡是依赖 GLX/Mali 的应用（Qt、glmark2、带 OpenGL 的浏览器）都会出同样的错误，只是有的程序会软渲染凑合运行，有的会直接崩溃或掉帧。  
- 要彻底解决，还是得把 libGL/libEGL 指向 Mali 版本、确保 rockchip_dri.so 被 GLVND 正确加载，再 `ldconfig`、重启验证；否则 Qt 只能靠软件路径，性能和 NPU 后续整合都会受限。


**建议优先级**

- **先切换到自管 GStreamer 管线**（立即执行）  
  - 你的摄像头功能和后续 NPU 推理都需要掌握原始视频流，GStreamer+appsink 是最佳形态；这一步不依赖 GPU，能先稳定工作，也便于后面接 RKNN。  
  - Qt 里只负责嵌入/显示和信号槽逻辑，避免 OpenGL 依赖，现状马上可用。

- **在此基础上，继续修复 Mali/OpenGL 驱动**（中期推进）  
  - 即便已经换成 GStreamer，桌面和其他图形应用仍会因 llvmpipe 占 CPU。恢复 libmali 可以提升整体性能，也为将来需要 GL 的功能留路。  
  - 修复手段：更新厂商固件或手工把 libGL/EGL 软链接指向 libmali，`ldconfig` 后重启验证 `glxinfo -B` 变成 Mali-G52。

- **不建议回到 QtMultimedia 方案**  
  - 它受限于 OpenGL 渲染，即使修好驱动，也不利于后续的零拷贝、RKNN 集成，维护价值较低。

所以当前最佳路线是：立即用 GStreamer 管道+appsink 替换 QtMultimedia，管线中预留 RGA/RKNN 接口；然后并行推进 Mali 驱动修复，待 GPU 恢复后整个系统性能都会上一个台阶。


可以先暂缓恢复 GPU 驱动，直接推进 NPU 推理路线，但请确认以下几点：  
- 当前方案只依赖 `librknnrt`、`/dev/rknpu` 与 RGA（`/dev/rga`），它们与 GPU 驱动无关联，可独立工作。  
- Qt 前端若仍基于 Widgets + GStreamer `ximagesink`，缺少 GPU 驱动仅意味着渲染退回软件路径，预览仍可跑，只是 UI 可能占用更多 CPU。  
- 若后续需要 Qt Quick/OpenGL 或 GStreamer 的 GL sink，再补 GPU 驱动即可；这项工作与 NPU 推理流水线解耦。

**建议下一步**  
1. 按文档第 3 部分准备 NPU 运行时（部署 `librknnrt.so`、RGA 头/库）。  
2. 在 PC 端转换 YOLO 模型（`target_platform='rk3566'`），将 `.rknn` 下发到板子。  
3. 搭建推理 worker（RGA 预处理 + RKNN 推理 + C++ 后处理），集成到 Qt 线程模型中。

## npu 单图验证

- 你现在已经能用 gstreamer 把摄像头画面送进 Qt/Appsink，这个前端不需要马上改。只要保证 appsink 里拿到的是可直接映射成 `cv::Mat`/`QImage` 的内存块（例如 RGB/BGR），就能把它交给现有 `YoloV5Runner`。  
- 在这一阶段，你完全可以沿用当前的 CPU 预处理链：`cv::cvtColor`（若需要从 BGR→RGB）、`cv::resize` 到模型输入大小，再调用 `rknn_inputs_set → rknn_run → post_process`。RK3566 的 A55 做 640×640 缩放+颜色转换大约 6–8 ms，一秒十几帧的视频实验就能跑通整条 “摄像头→NPU→Qt” 的闭环，验证逻辑正确、UI 交互、线程同步、绘制叠加都正常。  
- 这条纯 CPU 预处理路径的缺点是：分辨率一升高或想追求 25–30 FPS 时，A55 会成为瓶颈，CPU 占用飙升，也无法享受到零拷贝优势。但在“先把 NPU 检测叠到视频流”这一步，它的可维护性最高、出错面最小，利于快速验证。  
- 一旦你确认检测结果稳定、UI 叠加无误，再把重构焦点放到性能优化：  
  1. 引入 RGA 做 YUV/RGB 转换和缩放，替换掉大块的 `cv::resize/cvtColor`。  
  2. 尝试复用 gstreamer 的 MPP/RGA sink，把摄像头 NV12 buffer 直接映射到 RGA，再把 RGA 输出句柄传给 RKNN，完成“RGA→NPU”零拷贝流水线。  
  3. 根据 `RK3566 YOLO NPU 推理方案评估.md` 第 3.3 节的建议，把这些优化封装在 worker 线程里，保证 GUI 主线程保持响应。  
- 总结：**短期迭代可以先不引 RGA**，先跑通摄像头帧 → CPU 预处理 → `YoloV5Runner` → UI 叠加的闭环；待功能验证后再进入性能优化阶段，把 RGA/Librga 搭进来，把流水线升级成 “Camera → RGA → NPU → 后处理” 的最终形态。